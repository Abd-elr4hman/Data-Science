{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757382de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fede6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier,RandomForestClassifier, LogisticRegressionModel\n",
    "from pyspark.ml.feature import VectorAssembler, HashingTF, Tokenizer, StopWordsRemover, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98eae22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"sentiment analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137c69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_schema= StructType([\n",
    "    StructField(\"label\", IntegerType(), True),\n",
    "    StructField(\"tweet_id\", IntegerType(), True),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"query\", StringType(), True),\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac97dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df= spark.read.csv(r\"C:\\Users\\Abdelrahman\\project2\\tweetsGivenData\\training.1600000.processed.noemoticon.csv\",  header= True, schema= tweets_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b66baab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "|text                                                                                                           |label|\n",
      "+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!|0    |\n",
      "|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                      |0    |\n",
      "|my whole body feels itchy and like its on fire                                                                 |0    |\n",
      "|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. |0    |\n",
      "|@Kwesidei not the whole crew                                                                                   |0    |\n",
      "|Need a hug                                                                                                     |0    |\n",
      "|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?            |0    |\n",
      "|@Tatiana_K nope they didn't have it                                                                            |0    |\n",
      "|@twittera que me muera ?                                                                                       |0    |\n",
      "|spring break in plain city... it's snowing                                                                     |0    |\n",
      "+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data= tweets_df.select(col(\"tweet\").alias(\"text\"), col(\"label\").cast(\"Int\"))\n",
    "data.show(truncate= False, n= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21ab93",
   "metadata": {},
   "source": [
    "# Prepare and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3425e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "print(data.filter(\"tweet IS NULL\").count())\n",
    "print(data.filter(\"label IS NULL\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc9ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean trainig data\n",
    "\n",
    "def clean_text(c):\n",
    "    c = lower(c)\n",
    "    c = regexp_replace(c, \"^rt \", \"\")\n",
    "    c = regexp_replace(c, \"(https?\\://)\\S+\", \"\")\n",
    "    c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
    "    c = regexp_replace(c, \"\\d\", \"\")\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "def data_cleaning(data):\n",
    "    data_clean = data.withColumn('text', clean_text(data.text).alias(\"text\"))\n",
    "    data_clean = data_clean.na.replace('', None)\n",
    "    data_clean = data_clean.withColumn('text', trim(data_clean.text).alias(\"text\"))\n",
    "    return data_clean\n",
    "\n",
    "data_clean= data_cleaning(data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c626d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|text                                                                                                     |label|\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|is upset that he cant update his facebook by texting it and might cry as a result  school today also blah|0    |\n",
      "|kenichan i dived many times for the ball managed to save   the rest go out of bounds                     |0    |\n",
      "|my whole body feels itchy and like its on fire                                                           |0    |\n",
      "|nationwideclass no its not behaving at all im mad why am i here because i cant see you all over there    |0    |\n",
      "|kwesidei not the whole crew                                                                              |0    |\n",
      "|need a hug                                                                                               |0    |\n",
      "|loltrish hey  long time no see yes rains a bit only a bit  lol  im fine thanks  hows you                 |0    |\n",
      "|tatianak nope they didnt have it                                                                         |0    |\n",
      "|twittera que me muera                                                                                    |0    |\n",
      "|spring break in plain city its snowing                                                                   |0    |\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_clean.show(truncate= False,n= 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3568164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799999\n",
      "0\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "print(data_clean.filter(\"label == 0\").count())\n",
    "print(data_clean.filter(\"label == 2\").count())\n",
    "print(data_clean.filter(\"label == 4\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4eda1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799999\n",
      "0\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "data_clean= data_clean.na.replace(4, 1)\n",
    "print(data_clean.filter(\"label == 0\").count())\n",
    "print(data_clean.filter(\"label == 2\").count())\n",
    "print(data_clean.filter(\"label == 1\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caff74",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e3d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stages\n",
    "#indexer= StringIndexer(inputCol= \"label_text\", outputCol= \"label\")\n",
    "tokenizer= Tokenizer(inputCol= \"text\", outputCol= \"SentimentWords\")\n",
    "swr= StopWordsRemover(inputCol= tokenizer.getOutputCol(), outputCol= \"meaningfullWords\")\n",
    "hashTF= HashingTF(inputCol= swr.getOutputCol(), outputCol= \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3d441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate pipleine\n",
    "pipeline = Pipeline(stages=[tokenizer, swr, hashTF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f816c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "piped_data = pipeline.fit(data_clean).transform(data_clean)\n",
    "training, test = piped_data.randomSplit([.9, .1])\n",
    "\n",
    "classifier= LogisticRegression(labelCol= \"label\", featuresCol= \"features\", maxIter= 10, regParam=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fdec9",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea15f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as evals\n",
    "\n",
    "# Create a BinaryClassificationEvaluator\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e77e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tuning submodule\n",
    "import pyspark.ml.tuning as tune\n",
    "\n",
    "# Create the parameter grid\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# Add the hyperparameter\n",
    "grid = grid.addGrid(classifier.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(classifier.elasticNetParam, [0, 1])\n",
    "\n",
    "# Build the grid\n",
    "grid = grid.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea293d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CrossValidator\n",
    "cv = tune.CrossValidator(estimator=classifier,\n",
    "                         estimatorParamMaps=grid,\n",
    "                         evaluator=evaluator\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a424d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Call lr.fit()\\nmodels  = cv.fit(training)\\n\\n\\n# Extract the best model\\nbest_lr = models.bestModel\\n\\n# Print best_lr\\nprint(best_lr)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call lr.fit()\n",
    "models  = cv.fit(training)\n",
    "\n",
    "\n",
    "# Extract the best model\n",
    "best_lr = models.bestModel\n",
    "\n",
    "# Print best_lr\n",
    "print(best_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b354cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= classifier.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c59aa",
   "metadata": {},
   "source": [
    "# Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a622fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fecf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|      SentimentWords|    meaningfullWords|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|a big angry spide...|    0|[a, big, angry, s...|[big, angry, spid...|(262144,[93587,11...|[2.06133141978092...|[0.88708759792833...|       0.0|\n",
      "|a bit hacked off ...|    0|[a, bit, hacked, ...|[bit, hacked, hun...|(262144,[25363,31...|[0.98803426734413...|[0.72869947854260...|       0.0|\n",
      "|a blessed sunday ...|    0|[a, blessed, sund...|[blessed, sunday,...|(262144,[39504,51...|[-1.1909756909738...|[0.23308447963403...|       1.0|\n",
      "|a bus full of kid...|    0|[a, bus, full, of...|[bus, full, kids,...|(262144,[50172,54...|[-1.4131660551966...|[0.19573516656649...|       1.0|\n",
      "|a child after vac...|    0|[a, child, after,...|[child, vacations...|(262144,[130154,1...|[0.36842394022209...|[0.59107809200207...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(n= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b96bb58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7556721532919752\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "correctPrediction= prediction.filter(prediction[\"prediction\"]==prediction[\"label\"]).count()\n",
    "totalData= prediction.count()\n",
    "accuracy= correctPrediction/ totalData\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7ad32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find AUC\n",
    "Evaluator = evals.BinaryClassificationEvaluator()\n",
    "auc = Evaluator.evaluate(prediction, {Evaluator.metricName: \"areaUnderROC\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e594079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821824151755046\n"
     ]
    }
   ],
   "source": [
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440f74b",
   "metadata": {},
   "source": [
    "#  Tweets sentiment analysis streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3196f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(lines):\n",
    "    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"text\"))\n",
    "    words = words.na.replace('', None)\n",
    "    words = words.na.drop()\n",
    "    words = words.withColumn('text', regexp_replace('text', r'http\\S+', ''))\n",
    "    words = words.withColumn('text', regexp_replace('text', '@\\w+', ''))\n",
    "    words = words.withColumn('text', regexp_replace('text', '#', ''))\n",
    "    words = words.withColumn('text', regexp_replace('text', 'RT', ''))\n",
    "    words = words.withColumn('text', regexp_replace('text', ':', ''))\n",
    "    words = words.withColumn('text', regexp_replace('text', ',', ''))\n",
    "    words = words.withColumn('text', regexp_replace('text', ';', ''))\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the tweet data from socket\n",
    "lines = spark.readStream.format(\"socket\").option(\"host\", \"0.0.0.0\").option(\"port\", 5555).load()\n",
    "\n",
    "# Preprocess the data\n",
    "words= preprocessing(lines)\n",
    "words= pipeline.fit(words).transform(words)\n",
    "words= model.transform(words)\n",
    "words= words.select(\"text\", \"meaningfullWords\", \"features\", \"prediction\")\n",
    "\n",
    "query = words.writeStream.queryName(\"all_tweets\")\\\n",
    "        .outputMode(\"append\").format(\"parquet\")\\\n",
    "        .option(\"path\", \"./tweetsTable\")\\\n",
    "        .option(\"checkpointLocation\", \"./tweetsTableChec\")\\\n",
    "        .trigger(processingTime='60 seconds').start()\n",
    "query.awaitTermination()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed8565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
